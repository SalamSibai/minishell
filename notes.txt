1- scan inputs : to identifie the tokens 
2- check for validitiy - clean
3- create the abstract syntax tree


cases:
    1- redirecting to read from the standard input (heredoc)'<<'
        - next input must be a limiter
    2- reading from an infile
        - input must be a filename 
    3- redirecting input to a specific file '<'
        - next input must be a filename
    4- redirects output to a specific file '>'
        - next input must be a filename
    5- redirects output to append mode '>>'
        - next input must be a filename

ls -l | wc -l
	ls -l > file
	ls -l >> file
	ls -l < file
	ls -l << limiter

	ls -l | wc -l | ls -l > file
	ls -l | wc -l | ls -l >> file
/* examples: 
	ls -l | wc -l
	ls -l > file
	ls -l >> file
	ls -l < file
	ls -l << limiter

	ls -l | wc -l | ls -l > file
	ls -l | wc -l | ls -l >> file
	echo hisham > f2 cat 8 7 >> ss 77 66 << ju | < mn ct 5 4 3 

	hisham=123
bash-3.2$ export 1hisham=123
bash: export: `1hisham=123': not a valid identifier
bash-3.2$ export h1isham=123
bash-3.2$ ls
Makefile        debug           f2              minishell       parsing
README.md       env             includes        notes.txt       ss
bash.pdf        expansion       main.c          obj             validate
bash-3.2$ echo "hisham"
hisham
bash-3.2$ echo "his     ham"
his     ham
bash-3.2$ echo "$hisham"
123
bash-3.2$ echo '$hisham'
$hisham
bash-3.2$ echo "'$hisham'"
'123'
bash-3.2$ echo '"$hisham"'
"$hisham"
bash-3.2$ < mn ls -l obj includes
	


	/*
		execution flow:
			1- create t_data struct and initialize
				- split the PATH into the **path variable
				- store env in **envp
				- initialize and set t_env variable
			2- malloc for and initialize parse_data
			3- scan and fill in lexer & tokens
				- check the tokens, sets the type, and the string that represents the token.
				- increments the lexer (based on the token type)
				- this function also cleans up the string, making sure there are no spaces etc
			4- start filling in **cmd variable from the tokens
			5- if we have pipes:
				- initialzie and set the *pipe varibale from the lexer and the tokenizer
			6- if we have redirections:
				- "> outfile_name" we check the syntax correctness (has a filename or limiter after)
				- if everything is fine, we initialize and store
	*/




this could be an issue:   malloc and extra tokens (i believe im counting the qoutes)
		minishell$ ls"$X"                                              
		Token count: 4
		Token string: ls
		ID
		Token string: $X
		ID